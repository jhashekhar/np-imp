{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_mechanism_basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNm2WEXN82xx+s43F2NbU7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhashekhar/np-imp/blob/master/attention_mechanism_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M1LBUGOGzQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5j0MxXLQFi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8cde0c9-0975-4873-bbf2-a987e0814849"
      },
      "source": [
        "# vector of embeddings\n",
        "# let's say the number of the tokens/words or for the sake of simplicity the length of sentence is V = 3\n",
        "# with each V_i (embedding) be of size (1 x 2)\n",
        "# so [1, 6, 10]\n",
        "\n",
        "torch.Tensor([[0.2, 0.3], [0.3, 0.4], [0.7, 0.5]]).unsqueeze(0).shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPOvNEhpHPNY",
        "colab_type": "code",
        "outputId": "5592ed95-d0d7-4e8a-fb0f-63d4b03a62c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "torch.manual_seed(33)\n",
        "q = torch.randn(1, 3, 2)\n",
        "k = torch.randn(1, 3, 2)\n",
        "print(q, '\\n\\n' , k)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.1982, -0.3998],\n",
            "         [-0.3476, -0.2759],\n",
            "         [-2.3094, -1.0931]]]) \n",
            "\n",
            " tensor([[[-0.0808,  0.7721],\n",
            "         [-1.1370, -0.4773],\n",
            "         [-1.0679,  1.0688]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BVKTa-aJBcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q, k = q.reshape(1, -1), k.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNvS-xDT9_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4ed6b168-bb2e-44a4-d568-16edcfb6c859"
      },
      "source": [
        "print(q.size(), k.size())\n",
        "q.view(-1, 1).size()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6]) torch.Size([1, 6])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XSpGmvtLTGF",
        "colab_type": "code",
        "outputId": "84aa5693-60c2-411f-e177-81375aca796f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "torch.matmul(q.view(-1, 1), k)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0968,  0.9251, -1.3624, -0.5718, -1.2796,  1.2806],\n",
              "        [ 0.0323, -0.3087,  0.4546,  0.1908,  0.4270, -0.4273],\n",
              "        [ 0.0281, -0.2684,  0.3953,  0.1659,  0.3712, -0.3715],\n",
              "        [ 0.0223, -0.2130,  0.3137,  0.1317,  0.2946, -0.2948],\n",
              "        [ 0.1866, -1.7830,  2.6259,  1.1022,  2.4662, -2.4682],\n",
              "        [ 0.0883, -0.8440,  1.2430,  0.5217,  1.1674, -1.1683]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvMbiHjUIp18",
        "colab_type": "code",
        "outputId": "0478dc42-a6e0-4f48-a82f-035b4130ad38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# Softmax(similarity_measure)\n",
        "softmax = torch.nn.Softmax(dim=0)\n",
        "softmax(torch.matmul(q.view(-1, 1), k))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1443, 0.4647, 0.0117, 0.0642, 0.0142, 0.5918],\n",
              "        [0.1642, 0.1353, 0.0717, 0.1377, 0.0782, 0.1073],\n",
              "        [0.1635, 0.1409, 0.0676, 0.1343, 0.0740, 0.1134],\n",
              "        [0.1626, 0.1489, 0.0623, 0.1298, 0.0685, 0.1225],\n",
              "        [0.1916, 0.0310, 0.6290, 0.3425, 0.6011, 0.0139],\n",
              "        [0.1737, 0.0792, 0.1578, 0.1917, 0.1640, 0.0511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}